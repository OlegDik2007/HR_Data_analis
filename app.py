import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –æ –Ω–∞–π–º–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤",
    page_icon="üë•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
st.title("üë• –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –æ –Ω–∞–π–º–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
st.markdown("---")

# ==========================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ==========================

def find_date_column(df):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü, –∫–æ—Ç–æ—Ä—ã–π –ø–æ—Ö–æ–∂ –Ω–∞ –¥–∞—Ç—É, –∏–ª–∏ None."""
    date_columns = []
    for col in df.columns:
        if any(k in col.lower() for k in ['date', '–¥–∞—Ç–∞', 'time', '–≤—Ä–µ–º—è']):
            date_columns.append(col)
    if not date_columns:
        return None
    return date_columns[0]

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –≥–æ–¥–∞–º (–æ–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –∏ –±–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–∞—è)
def apply_year_filter(df, selected_year):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä –ø–æ –≥–æ–¥—É –∫ DataFrame"""
    if selected_year == "–í—Å–µ –≤—Ä–µ–º—è":
        return df

    # normalize to int if possible
    try:
        selected_year = int(selected_year)
    except:
        pass

    date_col = find_date_column(df)
    if not date_col:
        st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã —Å –¥–∞—Ç–∞–º–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≥–æ–¥–∞–º")
        return df

    try:
        df = df.copy()
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
        filtered_df = df[df[date_col].dt.year == selected_year].copy()
        st.info(f"üìÖ –ü—Ä–∏–º–µ–Ω–µ–Ω —Ñ–∏–ª—å—Ç—Ä –ø–æ –≥–æ–¥—É: {selected_year}. –ù–∞–π–¥–µ–Ω–æ {len(filtered_df)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {len(df)}")
        return filtered_df
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –≥–æ–¥—É: {e}")
        return df

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–¥–æ–≤
def get_available_years(df):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≥–æ–¥–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
    years = ["–í—Å–µ –≤—Ä–µ–º—è"]
    date_col = find_date_column(df)
    if date_col:
        try:
            df = df.copy()
            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
            available_years_list = sorted(df[date_col].dt.year.dropna().unique().astype(int))
            years.extend(available_years_list)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≥–æ–¥—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö: {e}")
    return years

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
@st.cache_data
def load_builtin_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –Ω–∞–π–º–µ"""
    try:
        csv_file = "merge-csv.com__68b9ee302f5dd.csv"
        encodings = ['utf-8', 'latin1', 'cp1251']
        df = None
        for encoding in encodings:
            try:
                df = pd.read_csv(
                    csv_file,
                    encoding=encoding,
                    skiprows=3,
                    header=0,
                    engine='python'
                )
                st.success(f"‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π: {encoding}")
                break
            except UnicodeDecodeError:
                continue
            except Exception as e:
                st.warning(f"–ü–æ–ø—ã—Ç–∫–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {encoding} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
                continue
        if df is not None:
            return df
        else:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            return None
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
@st.cache_data
def load_data(uploaded_file):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame"""
    try:
        if uploaded_file is not None:
            encodings = ['utf-8', 'latin1', 'cp1251']
            for encoding in encodings:
                try:
                    df = pd.read_csv(uploaded_file, encoding=encoding)
                    return df
                except UnicodeDecodeError:
                    continue
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç –∫–æ–¥–∏—Ä–æ–≤–∫–∏.")
            return None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {e}")
        return None

# ==========================
# –ê–ù–ê–õ–ò–¢–ò–ß–ï–°–ö–ò–ï –ë–õ–û–ö–ò
# ==========================

def analyze_data(df):
    """–ü—Ä–æ–≤–æ–¥–∏—Ç –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
    st.subheader("üìä –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π", len(df))
    with col2:
        st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–æ–ª–±—Ü–æ–≤", len(df.columns))
    with col3:
        missing_values = df.isnull().sum().sum()
        st.metric("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è", missing_values)
    with col4:
        memory_usage = df.memory_usage(deep=True).sum() / 1024 / 1024
        st.metric("–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö (–ú–ë)", f"{memory_usage:.2f}")

    st.subheader("üìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö")
    col_info_data = []
    for col in df.columns:
        try:
            missing_count = df[col].isnull().sum()
            unique_count = df[col].nunique()
            dtype_str = str(df[col].dtype)
            sample_values = df[col].dropna().head(3).astype(str).tolist()
            sample_str = ", ".join(sample_values) if sample_values else "N/A"
            col_info_data.append({
                '–°—Ç–æ–ª–±–µ—Ü': col,
                '–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö': dtype_str,
                '–ü—Ä–æ–ø—É—â–µ–Ω–æ': missing_count,
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö': unique_count,
                '–ü—Ä–∏–º–µ—Ä—ã': sample_str
            })
        except Exception as e:
            col_info_data.append({
                '–°—Ç–æ–ª–±–µ—Ü': col,
                '–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö': '–û—à–∏–±–∫–∞',
                '–ü—Ä–æ–ø—É—â–µ–Ω–æ': 0,
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö': 0,
                '–ü—Ä–∏–º–µ—Ä—ã': f'–û—à–∏–±–∫–∞: {str(e)}'
            })
    col_info = pd.DataFrame(col_info_data)
    st.dataframe(col_info, width='stretch')
    return col_info

def detailed_hiring_analysis(df):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞–π–º–∞ —Å —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç—å"""
    st.subheader("üéØ –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞–π–º–∞")
    hiring_columns = []
    for col in df.columns:
        col_lower = col.lower()
        if any(keyword in col_lower for keyword in ['hire', '–Ω–∞–π–º', '–ø—Ä–∏–Ω—è—Ç', '—Å—Ç–∞—Ç—É—Å', '—Ä–µ–∑—É–ª—å—Ç–∞—Ç', 'outcome', 'status']):
            hiring_columns.append(col)

    if hiring_columns:
        st.write(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã –Ω–∞–π–º–∞: {hiring_columns}")
        main_hiring_col = hiring_columns[0]
        st.write(f"**–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–æ–ª–±–µ—Ü:** {main_hiring_col}")

        hiring_dist = df[main_hiring_col].value_counts()
        col1, col2 = st.columns(2)
        with col1:
            st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤ –Ω–∞–π–º–∞:**")
            st.dataframe(hiring_dist)
        with col2:
            fig = px.pie(values=hiring_dist.values, names=hiring_dist.index, title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤ –Ω–∞–π–º–∞")
            st.plotly_chart(fig, width="stretch")

        st.subheader("üèÜ –ê–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
        success_keywords = ['active', 'approved', '–Ω–∞–π–º', '–ø—Ä–∏–Ω—è—Ç', '—É—Å–ø–µ—Ö']
        success_statuses = []
        for status in hiring_dist.index:
            status_lower = str(status).lower()
            if any(keyword in status_lower for keyword in success_keywords):
                success_statuses.append(status)

        if success_statuses:
            st.write(f"**–£—Å–ø–µ—à–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã:** {success_statuses}")
            successful_df = df[df[main_hiring_col].isin(success_statuses)]
            st.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:** {len(successful_df)}")

            if 'Worklist' in df.columns:
                st.write("**–î–æ–ª–∂–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—à–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:**")
                worklist_success = successful_df['Worklist'].value_counts()
                fig = px.bar(x=worklist_success.values, y=worklist_success.index, title="–î–æ–ª–∂–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—à–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", orientation='h')
                st.plotly_chart(fig, width="stretch")

            if 'State' in df.columns:
                st.write("**–ì–µ–æ–≥—Ä–∞—Ñ–∏—è —É—Å–ø–µ—à–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:**")
                state_success = successful_df['State'].value_counts().head(10)
                fig = px.bar(x=state_success.values, y=state_success.index, title="–¢–æ–ø-10 —à—Ç–∞—Ç–æ–≤ —É—Å–ø–µ—à–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", orientation='h')
                st.plotly_chart(fig, width="stretch")

        st.subheader("üìç –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–∞–π–º–∞")
        source_columns = []
        for col in df.columns:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in ['source', '–∏—Å—Ç–æ—á–Ω–∏–∫', 'recruiter', '—Ä–µ–∫—Ä—É—Ç–µ—Ä']):
                source_columns.append(col)

        if source_columns:
            st.write(f"**–°—Ç–æ–ª–±—Ü—ã –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:** {source_columns}")
            for source_col in source_columns:
                st.write(f"**–ê–Ω–∞–ª–∏–∑ —Å—Ç–æ–ª–±—Ü–∞:** {source_col}")
                source_dist = df[source_col].value_counts().head(10)
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**–¢–æ–ø-10 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:**")
                    st.dataframe(source_dist)
                with col2:
                    fig = px.pie(values=source_dist.values, names=source_dist.index, title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ {source_col}")
                    st.plotly_chart(fig, width="stretch")

                if success_statuses:
                    st.write("**–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω—ã—Ö):**")
                    source_effectiveness = {}
                    for source in source_dist.index:
                        if pd.notna(source) and source != "":
                            total_from_source = len(df[df[source_col] == source])
                            successful_from_source = len(df[(df[source_col] == source) & (df[main_hiring_col].isin(success_statuses))])
                            effectiveness = (successful_from_source / total_from_source) * 100 if total_from_source > 0 else 0
                            source_effectiveness[source] = effectiveness
                    sorted_effectiveness = dict(sorted(source_effectiveness.items(), key=lambda x: x[1], reverse=True))
                    fig = px.bar(x=list(sorted_effectiveness.values()), y=list(sorted_effectiveness.keys()), title="–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–∞–π–º–∞ (%)", orientation='h')
                    st.plotly_chart(fig, width="stretch")

        st.subheader("‚è∞ –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑ –Ω–∞–π–º–∞")
        time_columns = [col for col in df.columns if any(keyword in col.lower() for keyword in ['date', '–¥–∞—Ç–∞', '–≤—Ä–µ–º—è', 'time', '–≥–æ–¥', 'year'])]
        if time_columns:
            st.write(f"**–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:** {time_columns}")
            for time_col in time_columns:
                try:
                    df[time_col] = pd.to_datetime(df[time_col], errors='coerce')
                    df_time = df.dropna(subset=[time_col])
                    if len(df_time) > 0:
                        st.write(f"**–ê–Ω–∞–ª–∏–∑ —Å—Ç–æ–ª–±—Ü–∞:** {time_col}")
                        df_time['–ú–µ—Å—è—Ü'] = df_time[time_col].dt.to_period('M')
                        monthly_data = df_time.groupby(['–ú–µ—Å—è—Ü', main_hiring_col]).size().unstack(fill_value=0)
                        recent_months = monthly_data.tail(24)
                        fig = px.line(recent_months, title=f"–¢—Ä–µ–Ω–¥ –Ω–∞–π–º–∞ –ø–æ –º–µ—Å—è—Ü–∞–º ({time_col})", labels={'value': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', 'index': '–ú–µ—Å—è—Ü'})
                        st.plotly_chart(fig, width="stretch")
                        df_time['–ì–æ–¥'] = df_time[time_col].dt.year
                        yearly_data = df_time.groupby(['–ì–æ–¥', main_hiring_col]).size().unstack(fill_value=0)
                        fig = px.bar(yearly_data, title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º ({time_col})", barmode='group')
                        st.plotly_chart(fig, width="stretch")
                except Exception as e:
                    st.write(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å {time_col}: {e}")
    else:
        st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã –Ω–∞–π–º–∞. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ —Å—Ç–æ–ª–±—Ü—ã:")
        selected_col = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:", df.columns)
        if selected_col:
            col_dist = df[selected_col].value_counts()
            col1, col2 = st.columns(2)
            with col1:
                st.write("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π:")
                st.dataframe(col_dist)
            with col2:
                fig = px.pie(values=col_dist.values, names=col_dist.index, title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ —Å—Ç–æ–ª–±—Ü–µ {selected_col}")
                st.plotly_chart(fig, width="stretch")

def analyze_tenure(df):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
    st.subheader("‚è±Ô∏è –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã")
    tenure_columns = []
    for col in df.columns:
        col_lower = col.lower()
        if any(keyword in col_lower for keyword in ['tenure', '—Å—Ç–∞–∂', '–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å', 'duration', '–º–µ—Å—è—Ü', '–º–µ—Å—è—Ü–µ–≤', '–ª–µ—Ç']):
            tenure_columns.append(col)

    if tenure_columns:
        st.write(f"–ù–∞–π–¥–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã —Å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—Ç—ã: {tenure_columns}")
        for col in tenure_columns:
            st.write(f"**–ê–Ω–∞–ª–∏–∑ —Å—Ç–æ–ª–±—Ü–∞: {col}**")
            tenure_stats = df[col].describe()
            st.write("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã:")
            st.dataframe(tenure_stats)
            fig = px.histogram(df, x=col, title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã ({col})", labels={'x': col, 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'})
            st.plotly_chart(fig, width="stretch")
            hiring_columns = [c for c in df.columns if any(keyword in c.lower() for keyword in ['hire', '–Ω–∞–π–º', '–ø—Ä–∏–Ω—è—Ç', '—Å—Ç–∞—Ç—É—Å'])]
            if hiring_columns:
                hiring_col = hiring_columns[0]
                fig = px.box(df, x=hiring_col, y=col, title=f"–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –Ω–∞–π–º–∞")
                st.plotly_chart(fig, width="stretch")
    else:
        st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Å—Ç–æ–ª–±—Ü—ã —Å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—Ç—ã")

def build_ml_model(df):
    """–°—Ç—Ä–æ–∏—Ç –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞–π–º–∞"""
    st.subheader("ü§ñ –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–π–º–∞")
    st.write("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (—Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è):")
    target_col = st.selectbox("–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è:", df.columns)

    if target_col:
        st.write(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {target_col}")
        df_clean = df.dropna(subset=[target_col])
        unique_targets = df_clean[target_col].nunique()
        st.write(f"**–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:** {unique_targets}")

        if unique_targets < 2:
            st.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2)")
            return

        target_counts = df_clean[target_col].value_counts()
        min_class_size = target_counts.min()

        if unique_targets > 100 or min_class_size < 2:
            st.warning(f"‚ö†Ô∏è **–ü—Ä–æ–±–ª–µ–º–∞ —Å –¥–∞–Ω–Ω—ã–º–∏:**")
            st.write(f"- –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {unique_targets}")
            st.write(f"- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Å–∞: {min_class_size}")

            st.subheader("üîß –í–∞—Ä–∏–∞–Ω—Ç—ã —Ä–µ—à–µ–Ω–∏—è:")
            col1, col2 = st.columns(2)

            with col1:
                st.write("**1. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤**")
                min_samples = st.slider(
                    "–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–ª–∞—Å—Å–∞:",
                    min_value=2, max_value=50, value=5,
                    help="–ö–ª–∞—Å—Å—ã —Å –º–µ–Ω—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–ø–∏—Å–µ–π –±—É–¥—É—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –≤ '–î—Ä—É–≥–∏–µ'"
                )

                if st.button("–ü—Ä–∏–º–µ–Ω–∏—Ç—å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É"):
                    df_grouped = df_clean.copy()
                    target_counts = df_clean[target_col].value_counts()
                    frequent_classes = target_counts[target_counts >= min_samples].index
                    df_grouped[target_col] = df_grouped[target_col].apply(lambda x: x if x in frequent_classes else '–î—Ä—É–≥–∏–µ')
                    st.success(f"‚úÖ –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∞! –¢–µ–ø–µ—Ä—å {df_grouped[target_col].nunique()} –∫–ª–∞—Å—Å–æ–≤")
                    new_counts = df_grouped[target_col].value_counts()
                    st.write("**–ù–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:**")
                    st.dataframe(new_counts, width='stretch')
                    df_clean = df_grouped

            with col2:
                st.write("**2. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑**")
                st.write("–í–º–µ—Å—Ç–æ ML –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Å—Ç–∏:")
                st.write("‚Ä¢ –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π")
                st.write("‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
                st.write("‚Ä¢ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π")
                if st.button("–ü–µ—Ä–µ–π—Ç–∏ –∫ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É"):
                    st.subheader("üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
                    if len(numeric_cols) > 1:
                        correlation_matrix = df_clean[numeric_cols].corr()
                        fig = px.imshow(correlation_matrix, title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —á–∏—Å–ª–æ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö", color_continuous_scale='RdBu', aspect='auto')
                        st.plotly_chart(fig, width='stretch')
                        strong_correlations = []
                        for i in range(len(numeric_cols)):
                            for j in range(i+1, len(numeric_cols)):
                                corr_value = correlation_matrix.iloc[i, j]
                                if abs(corr_value) > 0.5:
                                    strong_correlations.append({
                                        '–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è 1': numeric_cols[i],
                                        '–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è 2': numeric_cols[j],
                                        '–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è': round(corr_value, 3)
                                    })
                        if strong_correlations:
                            st.write("**–°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (>0.5):**")
                            st.dataframe(pd.DataFrame(strong_correlations), width='stretch')
                        else:
                            st.info("–°–∏–ª—å–Ω—ã—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                    else:
                        st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                    return

            if 'df_grouped' not in locals():
                st.info("üëÜ –í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –≤—ã—à–µ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è")
                return

        st.write(f"**–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Å–∞:** {min_class_size}")
        st.success("‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è!")

        st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤:**")
        target_counts = df_clean[target_col].value_counts()
        st.dataframe(target_counts, width='stretch')

        df_encoded = df_clean.copy()

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–∞—Ç
        date_columns = []
        for col in df_encoded.columns:
            if df_encoded[col].dtype == 'datetime64[ns]' or 'date' in col.lower() or 'time' in col.lower():
                date_columns.append(col)

        for col in date_columns:
            if col != target_col:
                try:
                    df_encoded[f'{col}_year'] = df_encoded[col].dt.year
                    df_encoded[f'{col}_month'] = df_encoded[col].dt.month
                    df_encoded[f'{col}_day'] = df_encoded[col].dt.day
                    df_encoded[f'{col}_dayofweek'] = df_encoded[col].dt.dayofweek
                    df_encoded = df_encoded.drop(columns=[col])
                    st.info(f"üìÖ –°—Ç–æ–ª–±–µ—Ü {col} –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω –≤ —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
                except Exception as e:
                    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–æ–π {col}: {e}")
                    df_encoded = df_encoded.drop(columns=[col])

        categorical_cols = df_encoded.select_dtypes(include=['object']).columns
        numerical_cols = df_encoded.select_dtypes(include=[np.number]).columns

        label_encoders = {}
        for col in categorical_cols:
            if col != target_col:
                try:
                    le = LabelEncoder()
                    df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))
                    label_encoders[col] = le
                except Exception as e:
                    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–æ–ª–±–µ—Ü {col}: {e}")
                    df_encoded = df_encoded.drop(columns=[col])

        target_encoder = LabelEncoder()
        df_encoded[target_col] = target_encoder.fit_transform(df_encoded[target_col].astype(str))

        feature_cols = [col for col in df_encoded.select_dtypes(include=[np.number]).columns if col != target_col]

        if len(feature_cols) > 0:
            X = df_encoded[feature_cols]
            y = df_encoded[target_col]
            st.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** {len(feature_cols)}")
            st.write(f"**–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö:** {len(X)} –∑–∞–ø–∏—Å–µ–π")

            st.write("**–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**")
            feature_info = pd.DataFrame({
                '–ü—Ä–∏–∑–Ω–∞–∫': feature_cols,
                '–¢–∏–ø': [str(df_encoded[col].dtype) for col in feature_cols],
                '–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π': [df_encoded[col].nunique() for col in feature_cols]
            })
            st.dataframe(feature_info, width='stretch')

            missing_values = X.isnull().sum().sum()
            if missing_values > 0:
                st.warning(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {missing_values} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö")
                X = X.fillna(X.mean())
                st.info("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞–ø–æ–ª–Ω–µ–Ω—ã —Å—Ä–µ–¥–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏")

            can_stratify = all(target_counts >= 2)
            if can_stratify:
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
            else:
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                st.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –±–µ–∑ stratify –∏–∑-–∑–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∫–ª–∞—Å—Å–∞—Ö")

            st.write(f"üìä –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_train)}")
            st.write(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {len(X_test)}")

            try:
                model = RandomForestClassifier(n_estimators=100, random_state=42)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)

                st.write("**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏:**")
                col1, col2 = st.columns(2)
                with col1:
                    st.write("–û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
                    report = classification_report(y_test, y_pred, output_dict=True)
                    report_df = pd.DataFrame(report).transpose()
                    st.dataframe(report_df, width='stretch')
                with col2:
                    st.write("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
                    cm = confusion_matrix(y_test, y_pred)
                    fig = px.imshow(cm, labels=dict(x="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ", y="–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ"),
                                    x=target_encoder.classes_, y=target_encoder.classes_,
                                    title="–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
                    st.plotly_chart(fig, width='stretch')

                feature_importance = pd.DataFrame({'–ü—Ä–∏–∑–Ω–∞–∫': feature_cols, '–í–∞–∂–Ω–æ—Å—Ç—å': model.feature_importances_}).sort_values('–í–∞–∂–Ω–æ—Å—Ç—å', ascending=False)
                st.write("**–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**")
                fig = px.bar(feature_importance.head(10), x='–í–∞–∂–Ω–æ—Å—Ç—å', y='–ü—Ä–∏–∑–Ω–∞–∫', title="–¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", orientation='h')
                st.plotly_chart(fig, width='stretch')

                st.write("**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**")
                st.write("–í–≤–µ–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
                input_data = {}
                cols_per_row = 3
                for i, col in enumerate(feature_cols[:10]):
                    if i % cols_per_row == 0:
                        cols = st.columns(cols_per_row)
                    with cols[i % cols_per_row]:
                        if col in categorical_cols:
                            unique_vals = df_clean[col].unique()
                            input_data[col] = st.selectbox(f"{col}:", unique_vals)
                        else:
                            input_data[col] = st.number_input(f"{col}:", value=float(df_clean[col].mean()))
                if st.button("–°–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"):
                    input_df = pd.DataFrame([input_data])
                    for col in categorical_cols:
                        if col in input_data and col in label_encoders:
                            try:
                                input_df[col] = label_encoders[col].transform([input_data[col]])[0]
                            except:
                                st.error(f"–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è {col}")
                                continue
                    try:
                        prediction = model.predict(input_df)[0]
                        prediction_proba = model.predict_proba(input_df)[0]
                        predicted_class = target_encoder.inverse_transform([prediction])[0]
                        st.success(f"**–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:** {predicted_class}")
                        st.write("**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤:**")
                        proba_df = pd.DataFrame({'–ö–ª–∞—Å—Å': target_encoder.classes_, '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': prediction_proba}).sort_values('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', ascending=False)
                        st.dataframe(proba_df, width='stretch')
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
        else:
            st.error("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–æ–¥–µ–ª–∏")
            st.write("**–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:**")
            st.write("‚Ä¢ –í—Å–µ —Å—Ç–æ–ª–±—Ü—ã —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–æ–ª—å–∫–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
            st.write("‚Ä¢ –°—Ç–æ–ª–±—Ü—ã —Å –¥–∞—Ç–∞–º–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å")
            st.write("‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

def advanced_data_analysis(df):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    st.subheader("üîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
    st.subheader("üìä –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        total_cells = df.shape[0] * df.shape[1]
        missing_percentage = (df.isnull().sum().sum() / total_cells) * 100
        st.metric("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", f"{missing_percentage:.1f}%")
    with col2:
        duplicate_rows = df.duplicated().sum()
        st.metric("–î—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Å—Ç—Ä–æ–∫–∏", duplicate_rows)
    with col3:
        numeric_cols = len(df.select_dtypes(include=[np.number]).columns)
        st.metric("–ß–∏—Å–ª–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã", numeric_cols)
    with col4:
        categorical_cols = len(df.select_dtypes(include=['object']).columns)
        st.metric("–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã", categorical_cols)

    if 'State' in df.columns:
        st.subheader("üó∫Ô∏è –ì–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
        col1, col2 = st.columns(2)
        with col1:
            state_counts = df['State'].value_counts().head(15)
            fig = px.bar(x=state_counts.values, y=state_counts.index, title="–¢–æ–ø-15 —à—Ç–∞—Ç–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", orientation='h')
            st.plotly_chart(fig, width="stretch")
        with col2:
            st.write("**–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —à—Ç–∞—Ç–∞–º:**")
            state_summary = pd.DataFrame({'–®—Ç–∞—Ç': state_counts.index, '–ö–∞–Ω–¥–∏–¥–∞—Ç—ã': state_counts.values, '–ü—Ä–æ—Ü–µ–Ω—Ç': (state_counts.values / len(df)) * 100})
            st.dataframe(state_summary, width="stretch")

    if 'Last App Date' in df.columns:
        st.subheader("‚è∞ –í—Ä–µ–º–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏–∑")
        try:
            df = df.copy()
            df['Last App Date'] = pd.to_datetime(df['Last App Date'], errors='coerce')
            df_time = df.dropna(subset=['Last App Date'])
            if len(df_time) > 0:
                df_time['–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏'] = df_time['Last App Date'].dt.day_name()
                df_time['–ú–µ—Å—è—Ü'] = df_time['Last App Date'].dt.month_name()
                df_time['–ì–æ–¥'] = df_time['Last App Date'].dt.year
                col1, col2 = st.columns(2)
                with col1:
                    day_counts = df_time['–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏'].value_counts()
                    fig = px.pie(values=day_counts.values, names=day_counts.index, title="–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏")
                    st.plotly_chart(fig, width="stretch")
                with col2:
                    month_counts = df_time['–ú–µ—Å—è—Ü'].value_counts()
                    fig = px.bar(x=month_counts.index, y=month_counts.values, title="–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –º–µ—Å—è—Ü–∞–º")
                    st.plotly_chart(fig, width="stretch")
                yearly_trend = df_time['–ì–æ–¥'].value_counts().sort_index()
                fig = px.line(x=yearly_trend.index, y=yearly_trend.values, title="–¢—Ä–µ–Ω–¥ –Ω–∞–π–º–∞ –ø–æ –≥–æ–¥–∞–º", labels={'x': '–ì–æ–¥', 'y': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞—è–≤–æ–∫'})
                st.plotly_chart(fig, width="stretch")
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {e}")

def hiring_effectiveness_analysis(df):
    """–ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞–π–º–∞ –∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —É—Å–ø–µ—Ö–∞"""
    st.subheader("üéØ –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞–π–º–∞")
    status_col = None
    for col in df.columns:
        if 'status' in col.lower():
            status_col = col
            break

    if status_col:
        st.write(f"**–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Å—Ç–æ–ª–±—Ü—É:** {status_col}")
        success_patterns = ['active', 'approved', 'hired', 'success']
        success_statuses = []
        for status in df[status_col].unique():
            if pd.notna(status):
                status_lower = str(status).lower()
                if any(pattern in status_lower for pattern in success_patterns):
                    success_statuses.append(status)

        if success_statuses:
            st.write(f"**–£—Å–ø–µ—à–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã:** {success_statuses}")
            total_candidates = len(df)
            successful_candidates = len(df[df[status_col].isin(success_statuses)])
            overall_effectiveness = (successful_candidates / total_candidates) * 100
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("–û–±—â–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", f"{overall_effectiveness:.1f}%")
            with col2:
                st.metric("–£—Å–ø–µ—à–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", successful_candidates)
            with col3:
                st.metric("–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ", total_candidates)

            if 'Worklist' in df.columns:
                st.subheader("üíº –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç—è–º")
                position_effectiveness = {}
                for position in df['Worklist'].unique():
                    if pd.notna(position):
                        position_df = df[df['Worklist'] == position]
                        position_total = len(position_df)
                        position_successful = len(position_df[position_df[status_col].isin(success_statuses)])
                        effectiveness = (position_successful / position_total) * 100 if position_total > 0 else 0
                        position_effectiveness[position] = {'total': position_total, 'successful': position_successful, 'effectiveness': effectiveness}
                sorted_positions = sorted(position_effectiveness.items(), key=lambda x: x[1]['effectiveness'], reverse=True)
                effectiveness_df = pd.DataFrame([{'–î–æ–ª–∂–Ω–æ—Å—Ç—å': pos, '–í—Å–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤': data['total'], '–£—Å–ø–µ—à–Ω—ã—Ö': data['successful'], '–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (%)': round(data['effectiveness'], 1)} for pos, data in sorted_positions])
                st.dataframe(effectiveness_df, width="stretch")
                fig = px.bar(x=[pos for pos, _ in sorted_positions], y=[data['effectiveness'] for _, data in sorted_positions], title="–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞–π–º–∞ –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç—è–º (%)", labels={'x': '–î–æ–ª–∂–Ω–æ—Å—Ç—å', 'y': '–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (%)'})
                st.plotly_chart(fig, width="stretch")

            if 'Recruiter' in df.columns:
                st.subheader("üë• –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–µ–∫—Ä—É—Ç–µ—Ä–æ–≤")
                recruiter_effectiveness = {}
                for recruiter in df['Recruiter'].unique():
                    if pd.notna(recruiter) and recruiter != "":
                        recruiter_df = df[df['Recruiter'] == recruiter]
                        recruiter_total = len(recruiter_df)
                        recruiter_successful = len(recruiter_df[recruiter_df[status_col].isin(success_statuses)])
                        effectiveness = (recruiter_successful / recruiter_total) * 100 if recruiter_total > 0 else 0
                        recruiter_effectiveness[recruiter] = {'total': recruiter_total, 'successful': recruiter_successful, 'effectiveness': effectiveness}
                sorted_recruiters = sorted(recruiter_effectiveness.items(), key=lambda x: x[1]['effectiveness'], reverse=True)
                top_recruiters = sorted_recruiters[:10]
                fig = px.bar(x=[rec for rec, _ in top_recruiters], y=[data['effectiveness'] for _, data in top_recruiters], title="–¢–æ–ø-10 —Ä–µ–∫—Ä—É—Ç–µ—Ä–æ–≤ –ø–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (%)", labels={'x': '–†–µ–∫—Ä—É—Ç–µ—Ä', 'y': '–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (%)'})
                st.plotly_chart(fig, width="stretch")
                recruiter_df = pd.DataFrame([{'–†–µ–∫—Ä—É—Ç–µ—Ä': rec, '–í—Å–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤': data['total'], '–£—Å–ø–µ—à–Ω—ã—Ö': data['successful'], '–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (%)': round(data['effectiveness'], 1)} for rec, data in top_recruiters])
                st.dataframe(recruiter_df, width="stretch")

def trends_and_patterns_analysis(df):
    """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö"""
    st.subheader("üìà –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 1:
        st.subheader("üîó –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –º–µ–∂–¥—É —á–∏—Å–ª–æ–≤—ã–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏")
        correlation_matrix = df[numeric_cols].corr()
        fig = px.imshow(correlation_matrix, title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —á–∏—Å–ª–æ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö", color_continuous_scale='RdBu', aspect='auto')
        st.plotly_chart(fig, width="stretch")
        strong_correlations = []
        for i in range(len(numeric_cols)):
            for j in range(i+1, len(numeric_cols)):
                corr_value = correlation_matrix.iloc[i, j]
                if abs(corr_value) > 0.5:
                    strong_correlations.append({'–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è 1': numeric_cols[i], '–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è 2': numeric_cols[j], '–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è': round(corr_value, 3)})
        if strong_correlations:
            st.write("**–°–∏–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (>0.5):**")
            st.dataframe(pd.DataFrame(strong_correlations), width="stretch")

    st.subheader("üìä –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π")
    if 'Score' in df.columns:
        col1, col2 = st.columns(2)
        with col1:
            fig = px.histogram(df, x='Score', title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", nbins=20)
            st.plotly_chart(fig, width="stretch")
        with col2:
            fig = px.box(df, y='Score', title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ (box plot)")
            st.plotly_chart(fig, width="stretch")

    if 'Worklist' in df.columns and 'State' in df.columns:
        st.subheader("üè¢ –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–æ–ª–∂–Ω–æ—Å—Ç—è–º –∏ —à—Ç–∞—Ç–∞–º")
        pivot_table = df.groupby(['Worklist', 'State']).size().unstack(fill_value=0)
        st.write("**–¢–æ–ø-5 —à—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –¥–æ–ª–∂–Ω–æ—Å—Ç–∏:**")
        for position in df['Worklist'].unique():
            if pd.notna(position) and position in pivot_table.index:
                position_data = pivot_table.loc[position].sort_values(ascending=False).head(5)
                fig = px.bar(x=position_data.values, y=position_data.index, title=f"–¢–æ–ø-5 —à—Ç–∞—Ç–æ–≤ –¥–ª—è {position}", orientation='h')
                st.plotly_chart(fig, width="stretch")

def create_dashboard(df):
    """–°–æ–∑–¥–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–∞—à–±–æ—Ä–¥ —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    st.subheader("üìä –î–∞—à–±–æ—Ä–¥ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π")
    if len(df) > 0:
        date_col = find_date_column(df)
        if date_col:
            try:
                df_temp = df.copy()
                df_temp[date_col] = pd.to_datetime(df_temp[date_col], errors='coerce')
                min_date = df_temp[date_col].min()
                max_date = df_temp[date_col].max()
                if pd.notna(min_date) and pd.notna(max_date):
                    st.info(f"üìÖ **–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞:** {min_date.strftime('%d.%m.%Y')} - {max_date.strftime('%d.%m.%Y')}")
            except:
                pass

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        total_candidates = len(df)
        st.metric("–í—Å–µ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", f"{total_candidates:,}")
    with col2:
        if 'Status' in df.columns:
            active_candidates = len(df[df['Status'].str.contains('Active|Approved', case=False, na=False)])
            st.metric("–ê–∫—Ç–∏–≤–Ω—ã—Ö/–ü—Ä–∏–Ω—è—Ç—ã—Ö", active_candidates)
        else:
            st.metric("–ê–∫—Ç–∏–≤–Ω—ã—Ö/–ü—Ä–∏–Ω—è—Ç—ã—Ö", "N/A")
    with col3:
        if 'State' in df.columns:
            unique_states = df['State'].nunique()
            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —à—Ç–∞—Ç–æ–≤", unique_states)
        else:
            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —à—Ç–∞—Ç–æ–≤", "N/A")
    with col4:
        if 'Worklist' in df.columns:
            unique_positions = df['Worklist'].nunique()
            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π", unique_positions)
        else:
            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π", "N/A")

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        if 'Recruiter' in df.columns:
            unique_recruiters = df['Recruiter'].nunique()
            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∫—Ä—É—Ç–µ—Ä–æ–≤", unique_recruiters)
        else:
            st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∫—Ä—É—Ç–µ—Ä–æ–≤", "N/A")
    with col2:
        date_col = 'Last App Date' if 'Last App Date' in df.columns else None
        if date_col:
            try:
                df_tmp = df.copy()
                df_tmp[date_col] = pd.to_datetime(df_tmp[date_col], errors='coerce')
                date_range = df_tmp[date_col].max() - df_tmp[date_col].min()
                st.metric("–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç", f"{date_range.days} –¥–Ω–µ–π")
            except:
                st.metric("–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç", "N/A")
        else:
            st.metric("–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç", "N/A")
    with col3:
        missing_data = df.isnull().sum().sum()
        st.metric("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π", f"{missing_data:,}")
    with col4:
        memory_usage = df.memory_usage(deep=True).sum() / 1024 / 1024
        st.metric("–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö", f"{memory_usage:.1f} –ú–ë")

    st.subheader("üí° –ë—ã—Å—Ç—Ä—ã–µ –∏–Ω—Å–∞–π—Ç—ã")
    col1, col2 = st.columns(2)
    with col1:
        if 'Status' in df.columns:
            st.write("**–¢–æ–ø-5 —Å—Ç–∞—Ç—É—Å–æ–≤:**")
            top_statuses = df['Status'].value_counts().head(5)
            for status, count in top_statuses.items():
                percentage = (count / len(df)) * 100
                st.write(f"‚Ä¢ {status}: {count:,} ({percentage:.1f}%)")
    with col2:
        if 'Worklist' in df.columns:
            st.write("**–¢–æ–ø-5 –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π:**")
            top_positions = df['Worklist'].value_counts().head(5)
            for position, count in top_positions.items():
                percentage = (count / len(df)) * 100
                st.write(f"‚Ä¢ {position}: {count:,} ({percentage:.1f}%)")

# ======== –ù–û–í–û–ï: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ 4 –ª–µ—Ç =========
def compare_years_analysis(df, selected_years):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ 4 –ª–µ—Ç –ø–æ –∫–ª—é—á–µ–≤—ã–º –º–µ—Ç—Ä–∏–∫–∞–º –∏ —Ç—Ä–µ–Ω–¥–∞–º."""
    st.subheader("üìÜ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º")

    if not selected_years:
        st.info("–í—ã–±–µ—Ä–∏—Ç–µ –¥–æ 4 –ª–µ—Ç —Å–ª–µ–≤–∞, —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏—Ç—å.")
        return
    if len(selected_years) > 4:
        st.warning("–ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º—É–º 4 –≥–æ–¥–∞. –ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –ø–µ—Ä–≤—ã–µ 4.")
        selected_years = selected_years[:4]

    date_col = find_date_column(df)
    if not date_col:
        st.error("–ù–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü —Å –¥–∞—Ç–∞–º–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ª–µ—Ç.")
        return

    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df['__year__'] = df[date_col].dt.year
    df['__month__'] = df[date_col].dt.to_period('M')

    cdf = df[df['__year__'].isin(selected_years)].copy()
    if cdf.empty:
        st.warning("–ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ª–µ—Ç.")
        return

    # –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç—É—Å–∞
    status_col = None
    for col in cdf.columns:
        if 'status' in col.lower():
            status_col = col
            break

    # KPI –ø–æ –≥–æ–¥–∞–º
    kpi_rows = []
    for y in selected_years:
        ydf = cdf[cdf['__year__'] == y]
        total = len(ydf)
        active = eff = None
        if status_col is not None:
            active = ydf[status_col].astype(str).str.contains('Active|Approved', case=False, na=False).sum()
            eff = (active / total * 100) if total else 0
        kpi_rows.append({
            "–ì–æ–¥": y,
            "–ó–∞—è–≤–æ–∫": total,
            "–ê–∫—Ç–∏–≤–Ω—ã—Ö/–ü—Ä–∏–Ω—è—Ç—ã—Ö": active if active is not None else "N/A",
            "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (%)": round(eff, 1) if eff is not None else "N/A"
        })
    st.dataframe(pd.DataFrame(kpi_rows), use_container_width=True)

    totals = cdf.groupby('__year__').size().reset_index(name='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
    fig = px.bar(totals, x='__year__', y='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ', title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞—è–≤–æ–∫ –ø–æ –≥–æ–¥–∞–º")
    st.plotly_chart(fig, use_container_width=True)

    monthly = (cdf.dropna(subset=['__month__'])
                 .groupby(['__month__', '__year__']).size()
                 .reset_index(name='–ó–∞—è–≤–æ–∫')
               ).sort_values('__month__')
    fig = px.line(monthly, x='__month__', y='–ó–∞—è–≤–æ–∫', color='__year__',
                  title="–ú–µ—Å—è—á–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –≥–æ–¥–∞–º",
                  labels={'__month__': '–ú–µ—Å—è—Ü'})
    st.plotly_chart(fig, use_container_width=True)

    if status_col is not None:
        st.subheader("üßæ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤ –ø–æ –≥–æ–¥–∞–º")
        status_df = (cdf.assign(_status=cdf[status_col].astype(str).fillna("Unknown"))
                       .groupby(['__year__', '_status']).size()
                       .reset_index(name='Count'))
        fig = px.bar(status_df, x='__year__', y='Count', color='_status',
                     title="–°—Ç–∞—Ç—É—Å—ã –ø–æ –≥–æ–¥–∞–º (—Å—Ç–µ–∫)", barmode='stack')
        st.plotly_chart(fig, use_container_width=True)

    if 'Worklist' in cdf.columns:
        st.subheader("üíº –¢–æ–ø –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π –ø–æ –≥–æ–¥–∞–º")
        topN = 5
        for y in selected_years:
            ydf = cdf[cdf['__year__'] == y]
            if ydf.empty:
                continue
            top_positions = ydf['Worklist'].value_counts().head(topN)
            fig = px.bar(x=top_positions.values, y=top_positions.index,
                         orientation='h', title=f"–¢–æ–ø-{topN} –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π ‚Äî {y}")
            st.plotly_chart(fig, use_container_width=True)

# ==========================
# –û–ë–©–ò–ô –†–ï–ù–î–ï–† –ò–ù–¢–ï–†–§–ï–ô–°–ê
# ==========================

def run_app(df):
    """–ï–¥–∏–Ω–æ–µ –º–µ—Å—Ç–æ –¥–ª—è —Å–∞–π–¥–±–∞—Ä–∞, —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏ —Ä–æ—É—Ç–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü (—á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥)."""
    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –†–∞–∑–º–µ—Ä: {df.shape[0]} —Å—Ç—Ä–æ–∫ √ó {df.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    st.info(f"""
    üìä **–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:**
    - **–ó–∞–ø–∏—Å–µ–π:** {df.shape[0]:,}
    - **–°—Ç–æ–ª–±—Ü–æ–≤:** {df.shape[1]}
    - **–ü–µ—Ä–∏–æ–¥:** –∞–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∞—Ç–µ
    - **–¢–∏–ø:** –î–∞–Ω–Ω—ã–µ –æ –Ω–∞–π–º–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
    """)

    # ---- –§–∏–ª—å—Ç—Ä –ø–æ –≥–æ–¥–∞–º ----
    st.sidebar.markdown("---")
    st.sidebar.title("üìÖ –§–∏–ª—å—Ç—Ä –ø–æ –≥–æ–¥–∞–º")

    available_years = get_available_years(df)  # includes "–í—Å–µ –≤—Ä–µ–º—è"

    # Single-year filter (for regular pages)
    selected_year = st.sidebar.selectbox(
        "–ì–æ–¥ –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:",
        available_years,
        help="–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≥–æ–¥ –∏–ª–∏ '–í—Å–µ –≤—Ä–µ–º—è' –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"
    )

    # Multi-year compare (up to 4)
    years_only = [y for y in available_years if y != "–í—Å–µ –≤—Ä–µ–º—è"]
    compare_years_selected = st.sidebar.multiselect(
        "–°—Ä–∞–≤–Ω–∏—Ç—å –≥–æ–¥—ã (–¥–æ 4):",
        years_only,
        max_selections=4,
        help="–í—ã–±–µ—Ä–∏—Ç–µ –¥–æ 4 –ª–µ—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"
    )

    # Apply single-year filter for non-compare pages
    filtered_df = apply_year_filter(df, selected_year)

    # ---- –ù–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º ----
    st.sidebar.markdown("---")
    st.sidebar.title("üìä –†–∞–∑–¥–µ–ª—ã –∞–Ω–∞–ª–∏–∑–∞")
    page = st.sidebar.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–¥–µ–ª:",
        [
            "–î–∞—à–±–æ—Ä–¥", "–û–±—â–∏–π –æ–±–∑–æ—Ä", "–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞–π–º–∞",
            "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞–π–º–∞", "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
            "–¢—Ä–µ–Ω–¥—ã –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã", "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã",
            "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ª–µ—Ç"
        ]
    )

    if page == "–î–∞—à–±–æ—Ä–¥":
        create_dashboard(filtered_df)
    elif page == "–û–±—â–∏–π –æ–±–∑–æ—Ä":
        analyze_data(filtered_df)
    elif page == "–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞–π–º–∞":
        detailed_hiring_analysis(filtered_df)
    elif page == "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞–π–º–∞":
        hiring_effectiveness_analysis(filtered_df)
    elif page == "–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑":
        advanced_data_analysis(filtered_df)
    elif page == "–¢—Ä–µ–Ω–¥—ã –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã":
        trends_and_patterns_analysis(filtered_df)
    elif page == "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã":
        analyze_tenure(filtered_df)
    elif page == "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ":
        build_ml_model(filtered_df)
    elif page == "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ª–µ—Ç":
        # –î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π df (–±–µ–∑ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞)
        compare_years_analysis(df, compare_years_selected)

# ==========================
# MAIN
# ==========================

def main():
    st.sidebar.title("üìÅ –î–∞–Ω–Ω—ã–µ")

    # 1) –ü—ã—Ç–∞–µ–º—Å—è –∞–≤—Ç–æ–∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    df = load_builtin_data()

    if df is not None:
        run_app(df)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–≤—Ç–æ—Ä–æ–π —Ñ–∞–π–ª)
        st.sidebar.markdown("---")
        st.sidebar.title("üì§ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        uploaded_file = st.sidebar.file_uploader(
            "–ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≤–æ–π CSV —Ñ–∞–π–ª",
            type=['csv'],
            help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π CSV —Ñ–∞–π–ª –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"
        )
        if uploaded_file is not None:
            st.info("üì§ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –µ–≥–æ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.")
    else:
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        st.info("üëÜ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV —Ñ–∞–π–ª –≤—Ä—É—á–Ω—É—é")

        # 2) –§–æ–ª–±—ç–∫: —Ä—É—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
        uploaded_file = st.sidebar.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ CSV —Ñ–∞–π–ª",
            type=['csv'],
            help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –Ω–∞–π–º–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"
        )
        if uploaded_file is not None:
            df = load_data(uploaded_file)
            if df is not None:
                run_app(df)

if __name__ == "__main__":
    main()
